{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau \n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version: \",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting image\n",
    "ctr = 0\n",
    "for expression in os.listdir(\"train/\"):\n",
    "    for i in range(1,6):\n",
    "        ctr += 1\n",
    "        plt.subplot(7,5,ctr)\n",
    "        img = load_img(\"train/\"+expression+\"/\"+os.listdir(\"train/\"+expression)[i],(48,48))\n",
    "        plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for expression in os.listdir(\"train/\"):\n",
    "    print(str(len(os.listdir(\"train/\"+expression)))+\" \"+expression+\" images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 48\n",
    "batch_size = 64\n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip = True)\n",
    "train_generator = datagen_train.flow_from_directory(\"train/\",\n",
    "                                                   target_size=(img_size, img_size),\n",
    "                                                   color_mode='grayscale',\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=True)\n",
    "\n",
    "datagen_validation = ImageDataGenerator(horizontal_flip = True)\n",
    "validation_generator = datagen_validation.flow_from_directory(\"test/\",\n",
    "                                                   target_size=(img_size, img_size),\n",
    "                                                   color_mode='grayscale',\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**our cnn model inspired by the following paper https://arxiv.org/abs/1307.0414**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st Conv layer\n",
    "model.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd Conv layer\n",
    "model.add(Conv2D(128, (5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd Conv layer\n",
    "model.add(Conv2D(512, (3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4th Conv layer\n",
    "model.add(Conv2D(512, (3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "validation_steps = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "# to save the weights of best model with highest validation accuracy\n",
    "checkpoint = ModelCheckpoint('model_weight.hs', monitor='val_accuracy',\n",
    "                             save_weights_only=True, mode='max', verbose=1)\n",
    "\n",
    "# reducing the Learning rate if no chnage in loss for some strps\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.00001, mode='auto')\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit(x=train_generator,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=validation_steps,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the weight to json\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open('model.json','w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
